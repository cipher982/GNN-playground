{"cells": [{"metadata": {"trusted": false}, "cell_type": "code", "source": "pass", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4</td><td>application_1605522689137_0006</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-32-23-118.ec2.internal:20888/proxy/application_1605522689137_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-32-22-148.ec2.internal:8042/node/containerlogs/container_1605522689137_0006_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n# %load_ext autoreload\n# %autoreload 2\n\n# %matplotlib inline", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport dask.dataframe as dd\n\n# import matplotlib.pyplot as plt\n\n# from tqdm import tqdm\n# tqdm.pandas() # use progress_apply instead of apply\n\nfrom dask.diagnostics import ProgressBar\nProgressBar().register()\n", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import logging\n\nimport os\nimport sys\nimport json\n# from pyspark.sql import SparkSession\n\nimport datetime\n\nimport boto3\n\nfrom s3fs import S3FileSystem\nfs = S3FileSystem()\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import explode, col", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Initiate Object"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "date_start = '2020-09-01'  #yyyy-mm-dd\ndate_end = '2020-10-01'    #yyyy-mm-dd\ndate_processed_on = '2020-10-14' #yyyy-mm-dd", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "config_step_z22 = {\n    'date_start': date_start, # 'YYYY-MM-DD'\n    'date_end': date_end, # 'YYYY-MM-DD',\n    'date_processed_on': date_processed_on, # 'YYYY-MM-DD',\n    'path_root': 's3://zeta-dc-ml/ai-audiences/',\n    }", "execution_count": 12, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "self = PrepUIMatrix(date_start=config_step_z22['date_start'],\n                    date_end=config_step_z22['date_end'],\n                    date_processed_on=config_step_z22['date_processed_on'],\n                    path_root=config_step_z22['path_root'],\n                   )", "execution_count": 13, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "self.generate_list_of_dates_to_process()", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "30", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "self.list_of_dates_to_process", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "[datetime.datetime(2020, 9, 1, 0, 0), datetime.datetime(2020, 9, 2, 0, 0), datetime.datetime(2020, 9, 3, 0, 0), datetime.datetime(2020, 9, 4, 0, 0), datetime.datetime(2020, 9, 5, 0, 0), datetime.datetime(2020, 9, 6, 0, 0), datetime.datetime(2020, 9, 7, 0, 0), datetime.datetime(2020, 9, 8, 0, 0), datetime.datetime(2020, 9, 9, 0, 0), datetime.datetime(2020, 9, 10, 0, 0), datetime.datetime(2020, 9, 11, 0, 0), datetime.datetime(2020, 9, 12, 0, 0), datetime.datetime(2020, 9, 13, 0, 0), datetime.datetime(2020, 9, 14, 0, 0), datetime.datetime(2020, 9, 15, 0, 0), datetime.datetime(2020, 9, 16, 0, 0), datetime.datetime(2020, 9, 17, 0, 0), datetime.datetime(2020, 9, 18, 0, 0), datetime.datetime(2020, 9, 19, 0, 0), datetime.datetime(2020, 9, 20, 0, 0), datetime.datetime(2020, 9, 21, 0, 0), datetime.datetime(2020, 9, 22, 0, 0), datetime.datetime(2020, 9, 23, 0, 0), datetime.datetime(2020, 9, 24, 0, 0), datetime.datetime(2020, 9, 25, 0, 0), datetime.datetime(2020, 9, 26, 0, 0), datetime.datetime(2020, 9, 27, 0, 0), datetime.datetime(2020, 9, 28, 0, 0), datetime.datetime(2020, 9, 29, 0, 0), datetime.datetime(2020, 9, 30, 0, 0)]", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(self.path_UI_COO_sizmek)\nprint(self.path_UI_COO_zync)\nprint(self.path_UI_COO_disqus)", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "s3://zeta-dc-ml/ai-audiences/user_activity_daily_sizmek_parquet_UI_COOmatrix/\ns3://zeta-dc-ml/ai-audiences/user_activity_daily_zync_parquet_UI_COOmatrix/\ns3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(self.path_UI_interactions_sizmek)\nself.path_UI_interactions_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z31_user_item_interactions_sizmek'\nself.path_UI_interactions_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z41_user_item_interactions_count_sizmek'\nself.path_I_count_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z51_item_count_count_sizmek'\nprint(self.path_UI_interactions_sizmek_)\nprint(self.path_UI_interactions_count_sizmek_)\nprint(self.path_I_count_count_sizmek_)\n\nprint('-----------------')\n\nprint(self.path_UI_interactions_zync)\nself.path_UI_interactions_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z32_user_item_interactions_zync'\nself.path_UI_interactions_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z42_user_item_interactions_count_zync'\nself.path_I_count_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z52_item_count_count_zync'\nprint(self.path_UI_interactions_zync_)\nprint(self.path_UI_interactions_count_zync_)\nprint(self.path_I_count_count_zync_)\n\nprint('-----------------')\n\nprint(self.path_UI_interactions_disqus)\nself.path_UI_interactions_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z33_user_item_interactions_disqus'\nself.path_UI_interactions_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z43_user_item_interactions_count_disqus'\nself.path_I_count_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z53_item_count_count_disqus'\nprint(self.path_UI_interactions_disqus_)\nprint(self.path_UI_interactions_count_disqus_)\nprint(self.path_I_count_count_disqus_)\n", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z21_user_item_interactions_sizmek\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z31_user_item_interactions_sizmek\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z41_user_item_interactions_count_sizmek\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z51_item_count_count_sizmek\n-----------------\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z22_user_item_interactions_zync\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z32_user_item_interactions_zync\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z42_user_item_interactions_count_zync\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z52_item_count_count_zync\n-----------------\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z23_user_item_interactions_disqus\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z33_user_item_interactions_disqus\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z43_user_item_interactions_count_disqus\ns3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z53_item_count_count_disqus", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# path_UI_COO_sizmek to consolidated_UI_COO_sizmek\n"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# path_list = self.gen_path_list(self.path_UI_COO_sizmek)\n# path_list = self.gen_path_list(self.path_UI_COO_zync)\npath_list = self.gen_path_list(self.path_UI_COO_disqus)\n\n\nprint(f'number of date partitions: {len(path_list)}')\nprint(f'first path: {path_list[0]}')\nprint(f'last path: {path_list[-1]}')\n\n", "execution_count": 80, "outputs": [{"output_type": "stream", "text": "number of buckets in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 209\nnumber of buckets that cannot be processed in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 0\nnumber of buckets that can be processed in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 209\n\n\nnumber of date partitions: 30\nfirst path: s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/dt=2020-09-01/*.parquet\nlast path: s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/dt=2020-09-30/*.parquet", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\ndf.printSchema()", "execution_count": 81, "outputs": [{"output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- zcodes: string (nullable = true)\n |-- count: long (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\ndf.printSchema()", "execution_count": 82, "outputs": [{"output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- zcodes: string (nullable = true)\n |-- count: long (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.write.parquet(self.path_UI_interactions_sizmek_)\n# df.write.parquet(self.path_UI_interactions_zync_)\ndf.write.parquet(self.path_UI_interactions_disqus_)\n", "execution_count": 84, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# UI matrix -> U-I_count matrix"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_sizmek_+'/*.parquet')\n# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_zync_+'/*.parquet')\ndf = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_disqus_+'/*.parquet')\n\n# df.printSchema()", "execution_count": 71, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.show(n=4)", "execution_count": 72, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\nprint(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\nprint(f'Schema of the dataframe is:')\ndf.printSchema()", "execution_count": 73, "outputs": [{"output_type": "stream", "text": "No. of partitions in the dataframe are: 500\nShape of the dataframe is 622231127 x 3\nSchema of the dataframe is:\nroot\n |-- user_id: string (nullable = true)\n |-- zcodes: string (nullable = true)\n |-- count: long (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.select(F.countDistinct(\"user_id\")).show()\ncount_distinct_cookies = (df.select(F.countDistinct(\"user_id\")).collect())[0][0]\ncount_distinct_cookies", "execution_count": 74, "outputs": [{"output_type": "stream", "text": "107645985", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.select(F.countDistinct(\"user_id\")).show()\ncount_distinct_zcodes = (df.select(F.countDistinct(\"zcodes\")).collect())[0][0]\ncount_distinct_zcodes", "execution_count": 75, "outputs": [{"output_type": "stream", "text": "726", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.groupBy(\"user_id\").count().orderBy(col(\"count\").desc()).show(n=5)", "execution_count": 76, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = df.groupBy(\"user_id\").count().orderBy(col(\"count\").desc())\ndf.printSchema()", "execution_count": 77, "outputs": [{"output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- count: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = df.withColumnRenamed('count','num_zcode')\ndf.printSchema()", "execution_count": 78, "outputs": [{"output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- num_zcode: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df.write.parquet(self.path_UI_interactions_count_sizmek_)\n# df.write.parquet(self.path_UI_interactions_count_zync_)\ndf.write.parquet(self.path_UI_interactions_count_disqus_)", "execution_count": 79, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# U-I_count matrix -> I_count-Count matrix"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_sizmek_+'/*.parquet')\n# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_zync_+'/*.parquet')\ndf = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_disqus_+'/*.parquet')\n", "execution_count": 125, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\nprint(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\nprint(f'Schema of the dataframe is:')\ndf.printSchema()", "execution_count": 126, "outputs": [{"output_type": "stream", "text": "No. of partitions in the dataframe are: 407\nShape of the dataframe is 107645985 x 2\nSchema of the dataframe is:\nroot\n |-- user_id: string (nullable = true)\n |-- num_zcode: long (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.select(F.sum('num_zcode')).collect()[0][0]", "execution_count": 127, "outputs": [{"output_type": "stream", "text": "622231127", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.show(n=5)", "execution_count": 128, "outputs": [{"output_type": "stream", "text": "+---------------+---------+\n|        user_id|num_zcode|\n+---------------+---------+\n| c6pmj1err6dvi7|      208|\n|c6keckis3f06age|      167|\n| c5vin6ddk7tbfq|      159|\n|c7etkq7138lnfjj|      158|\n| c6k1im741re0it|      156|\n+---------------+---------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = df.groupBy(\"num_zcode\").count().orderBy(col(\"num_zcode\"))", "execution_count": 129, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.printSchema()", "execution_count": 130, "outputs": [{"output_type": "stream", "text": "root\n |-- num_zcode: long (nullable = true)\n |-- count: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(f'number of unique num_zcode: {df.count()}')", "execution_count": 131, "outputs": [{"output_type": "stream", "text": "number of unique num_zcode: 156", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.show(n=5)", "execution_count": 132, "outputs": [{"output_type": "stream", "text": "+---------+--------+\n|num_zcode|   count|\n+---------+--------+\n|        1|11799633|\n|        2|13505642|\n|        3|17057432|\n|        4|13795956|\n|        5|11962812|\n+---------+--------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pandas_df = df.toPandas()", "execution_count": 133, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pandas_df.head()", "execution_count": 134, "outputs": [{"output_type": "stream", "text": "   num_zcode     count\n0          1  11799633\n1          2  13505642\n2          3  17057432\n3          4  13795956\n4          5  11962812", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# pandas_df.to_csv(self.path_I_count_count_sizmek_+'.csv', header=True, index=False)\n# pandas_df.to_csv(self.path_I_count_count_zync_+'.csv', header=True, index=False)\npandas_df.to_csv(self.path_I_count_count_disqus_+'.csv', header=True, index=False)", "execution_count": 135, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# I_count-Count matrix"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# pdf = pd.read_csv(self.path_I_count_count_sizmek_+'.csv')\n# pdf = pd.read_csv(self.path_I_count_count_zync_+'.csv')\npdf = pd.read_csv(self.path_I_count_count_disqus_+'.csv')", "execution_count": 136, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pdf.head()", "execution_count": 137, "outputs": [{"output_type": "stream", "text": "   num_zcode     count\n0          1  11799633\n1          2  13505642\n2          3  17057432\n3          4  13795956\n4          5  11962812", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# read email_cookie relations"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "path_email_email = 's3://zeta-dcp-prod-private-tables/persistent_identifier/pid_email_links/' + 'dt=2020-10-12/'", "execution_count": 139, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = spark.read.option(\"inferSchema\", True).orc(path_email_email +'/*')", "execution_count": 143, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.printSchema()", "execution_count": 144, "outputs": [{"output_type": "stream", "text": "root\n |-- email_md5: string (nullable = true)\n |-- link_md5: string (nullable = true)\n |-- weight: decimal(10,2) (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.show(n=5)", "execution_count": 145, "outputs": [{"output_type": "stream", "text": "+--------------------+--------------------+------+\n|           email_md5|            link_md5|weight|\n+--------------------+--------------------+------+\n|264976664fc3ba8c2...|bd4b1058985520e14...|  0.60|\n|e99aa9c2a3d1a509e...|16d70b42251956ae8...|  0.80|\n|a9ef211e912330863...|61856457c2d5bcf6b...|  0.80|\n|e4e4e071eb2909727...|14e0556227070d5ae...|  0.80|\n|96ae9883afd3ea217...|0243273cfc5f3d3e1...|  0.60|\n+--------------------+--------------------+------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\nprint(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\n# print(f'Schema of the dataframe is:')\n# df.printSchema()", "execution_count": 146, "outputs": [{"output_type": "stream", "text": "No. of partitions in the dataframe are: 75690\nShape of the dataframe is 156725840876 x 3", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "path_cookie_email = 's3://zeta-dcp-prod-private-tables/datacloud_cookie_emails_links_export/' + 'dt=2020-10-18/'", "execution_count": 5, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = spark.read.option(\"inferSchema\", True).orc(path_cookie_email +'/*')", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.printSchema()", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie: string (nullable = true)\n |-- email_md5: string (nullable = true)\n |-- last_connected: timestamp (nullable = true)\n |-- last_updated: timestamp (nullable = true)\n |-- pos: integer (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.show(n=5)", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "+--------------------+--------------------+-------------------+--------------------+---+\n|              cookie|           email_md5|     last_connected|        last_updated|pos|\n+--------------------+--------------------+-------------------+--------------------+---+\n|zync::0000003c-3b...|a65404227d3459880...|2020-06-26 16:00:32|2020-09-16 00:02:...|  1|\n|zync::000001ae-65...|7644401120d47b897...|               null|2020-09-16 00:02:...|  1|\n|zync::000004f1-de...|c4edd56ff9e2e2a23...|2019-09-27 21:43:54|2020-09-16 00:02:...|  1|\n|zync::000007df-b3...|c774117ef92260e3c...|2020-06-10 02:20:12|2020-09-16 00:02:...|  1|\n|zync::000007df-b3...|0a04a1e089d58a8da...|2020-05-28 16:27:02|2020-09-16 00:02:...|  2|\n+--------------------+--------------------+-------------------+--------------------+---+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\nprint(f'Shape of the dataframe is {df.count()}') # x {len(df.columns)}')\n# print(f'Schema of the dataframe is:')\n# df.printSchema()", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "No. of partitions in the dataframe are: 6375\nShape of the dataframe is 22087657290", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "path_cookie_cookie = 's3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/' + 'dt=2020-09-24/'\n", "execution_count": 18, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df = spark.read.option(\"inferSchema\", True).orc(path_cookie_cookie +'/*')", "execution_count": 20, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.printSchema()", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie: string (nullable = true)\n |-- relation: string (nullable = true)\n |-- last_connected: timestamp (nullable = true)\n |-- last_updated: timestamp (nullable = true)\n |-- pos: integer (nullable = true)\n |-- dt: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.show(n=5)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "+--------------------+--------------------+--------------+--------------------+---+----------+\n|              cookie|            relation|last_connected|        last_updated|pos|        dt|\n+--------------------+--------------------+--------------+--------------------+---+----------+\n|zync::69c55eb9-76...|sizmek::158224121...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n|zync::69c55eb9-76...|zync::69c55eb9-76...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n|sizmek::197630618...|disqus::c819ns0h3...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n|sizmek::197630618...|sizmek::197630618...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n|sizmek::165092110...|sizmek::165092110...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n+--------------------+--------------------+--------------+--------------------+---+----------+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "class PrepUIMatrix:\n\n    def __init__(self,\n                 date_start, # str in format YYYY-MM-DD\n                 date_end, # str in format YYYY-MM-DD\n                 date_processed_on, # str in format YYYY-MM-DD\n                 path_root='s3://zeta-dc-ml/ai-audiences/',\n                 ):\n\n        self.date_start = date_start\n        self.date_end = date_end\n        self.date_processed_on = date_processed_on\n\n        self.path_root = path_root\n\n        self.path_root_modeling = self.path_root + 'modeling/dt=' + date_processed_on + '/'\n\n        self.path_UI_COO_sizmek = self.path_root + 'user_activity_daily_sizmek_parquet_UI_COOmatrix/'\n        self.path_UI_COO_zync = self.path_root + 'user_activity_daily_zync_parquet_UI_COOmatrix/'\n        self.path_UI_COO_disqus = self.path_root + 'user_activity_daily_disqus_parquet_UI_COOmatrix/'\n\n        self.path_disqus_to_sizmek = self.path_root + 'datacloud_cookie_cookie_relations/disqus_to_sizmek/'\n        self.path_zync_to_sizmek = self.path_root + 'datacloud_cookie_cookie_relations/zync_to_sizmek/'\n\n        self.path_UI_interactions_sizmek = self.path_root_modeling + 'z21_user_item_interactions_sizmek'\n        self.path_UI_interactions_zync = self.path_root_modeling + 'z22_user_item_interactions_zync'\n        self.path_UI_interactions_disqus = self.path_root_modeling + 'z23_user_item_interactions_disqus'\n\n        self.path_UI_interactions_final = self.path_root_modeling + 'z01_user_item_interactions'\n\n        self.list_of_dates_to_process = None\n\n        self.date_processed_latest_zync_to_sizmek = None\n        self.date_processed_latest_disqus_to_sizmek = None\n\n    def generate_list_of_dates_to_process(self):\n        start = datetime.datetime.strptime(self.date_start, '%Y-%m-%d')\n        end = datetime.datetime.strptime(self.date_end, '%Y-%m-%d')\n        self.list_of_dates_to_process = [start + datetime.timedelta(days=x) for x in range(0, (end - start).days)]\n\n        print(len(self.list_of_dates_to_process))\n\n    @staticmethod\n    def get_list_of_all_dates_present(bucket, prefix):\n\n        s3 = boto3.client(\"s3\")\n        all_objects = s3.list_objects(Bucket=bucket,\n                                      Prefix=prefix,\n                                      Delimiter='/')\n\n        list_date_buckets = []\n        for o in all_objects.get('CommonPrefixes'):\n            list_date_buckets.append(o.get('Prefix'))\n        #     print(o.get('Prefix'))\n\n        print('number of buckets in s3://{}/{} are {}'.format(bucket, prefix, len(list_date_buckets)))\n\n        list_dates_present = [el.split('/')[-2].split('=')[-1] for el in list_date_buckets]\n\n        list_dates_that_can_be_processed = []\n\n        count = 0\n        for el in list_dates_present:\n            try:\n                list_dates_that_can_be_processed.append(datetime.datetime.strptime(el, '%Y-%m-%d'))\n            except:\n                count = count + 1\n                print('date partition that cannot be processed: {}'.format(el))\n\n        print('number of buckets that cannot be processed in s3://{}/{} are {}'.format(bucket, prefix, count))\n        print('number of buckets that can be processed in s3://{}/{} are {}'.format(bucket, prefix, len(\n            list_dates_that_can_be_processed)))\n\n        list_dates_that_can_be_processed.sort()\n\n        return list_dates_that_can_be_processed\n\n    def gen_path_list(self, path_UI_COO):\n\n        # The purpose of this function is to find the intersection of the {dates requested} with {dates present in data}\n        # This will be applied to all three tables individually\n        # Some sources might have missing dates\n\n        bucket = path_UI_COO.split('/')[2]\n        rest_of_path = os.path.join(*(path_UI_COO.split('/')[3:]))\n\n        list_of_dates_present = self.get_list_of_all_dates_present(bucket=bucket,\n                                                                   prefix=rest_of_path)\n\n        list_of_dates_available = list(set(self.list_of_dates_to_process).intersection(list_of_dates_present))\n        list_of_dates_available.sort()\n\n        print(''.format(len(list_of_dates_present)))\n        print(''.format(len(list_of_dates_available)))\n\n        path_list = [path_UI_COO + 'dt=' + date.strftime('%Y-%m-%d') + '/*.parquet' for date in list_of_dates_available]\n\n        return path_list\n\n    def get_latest_date_partition(self, path):\n\n        bucket = path.split('/')[2]\n        rest_of_path = os.path.join(*(path.split('/')[3:]))\n\n        list_of_all_dates_that_can_be_processed = self.get_list_of_all_dates_present(bucket=bucket,\n                                                                                     prefix=rest_of_path)\n        return list_of_all_dates_that_can_be_processed[-1].strftime('%Y-%m-%d')\n\n    def generate_sizmek_ui_matrix(self):\n        path_list = self.gen_path_list(self.path_UI_COO_sizmek)\n        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n        df.write.parquet(self.path_UI_interactions_sizmek)\n\n    def generate_disqus_ui_matrix(self):\n        # Disqus UI Matrix -> Disqus_Sizmek UI Matrix\n\n        work_on_date_partition = self.get_latest_date_partition(self.path_zync_to_sizmek)\n\n        # Read the latest Disqus to Sizmek Cookie Mapping\n        df_disqus_to_sizmek = spark.read.option(\"inferSchema\", True).parquet(self.path_disqus_to_sizmek + 'dt=' + work_on_date_partition + '/*.parquet')\n\n        path_list = self.gen_path_list(self.path_UI_COO_disqus)\n\n        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n\n        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n        df = df.join(df_disqus_to_sizmek, df.user_id == df_disqus_to_sizmek.cookie_disqus, 'inner')\n        df = df.select([explode(df.cookie_sizmek).alias('user_id'), 'zcodes', 'count'])\n\n        df.write.parquet(self.path_UI_interactions_disqus)\n\n    def generate_zync_ui_matrix(self):\n        # Zync UI Matrix -> Zync_Sizmek UI Matrix\n\n        work_on_date_partition = self.get_latest_date_partition(self.path_zync_to_sizmek)\n\n        # Read the latest Zync to Sizmek Cookie Mapping\n        df_zync_to_sizmek = spark.read.option(\"inferSchema\", True).parquet(self.path_zync_to_sizmek + 'dt=' + work_on_date_partition + '/*.parquet')\n\n        path_list = self.gen_path_list(self.path_UI_COO_zync)\n\n        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n\n        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n        df = df.join(df_zync_to_sizmek, df.user_id == df_zync_to_sizmek.cookie_zync, 'inner')\n        df = df.select([explode(df.cookie_sizmek).alias('user_id'), 'zcodes', 'count'])\n\n        df.write.parquet(self.path_UI_interactions_zync)\n\n    def generate_final_ui_matrix(self):\n\n        # Sizmek_UI_Final = Sizmek_UI + Zync_Sizmek_UI + Disqus_Sizmek_UI\n\n        path_list = [self.path_UI_interactions_sizmek + '/*.parquet',\n                     self.path_UI_interactions_zync + '/*.parquet',\n                     self.path_UI_interactions_disqus + '/*.parquet']\n\n        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n\n        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n\n        df.write.parquet(self.path_UI_interactions_final)\n\n#     def run_step(self):\n#         self.generate_list_of_dates_to_process()\n#         self.generate_sizmek_ui_matrix()\n#         self.generate_disqus_ui_matrix()\n#         self.generate_zync_ui_matrix()\n#         self.generate_final_ui_matrix()", "execution_count": 10, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}