{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>4</td><td>application_1605522689137_0006</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-32-23-118.ec2.internal:20888/proxy/application_1605522689137_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-32-22-148.ec2.internal:8042/node/containerlogs/container_1605522689137_0006_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas() # use progress_apply instead of apply\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "import datetime\n",
    "\n",
    "import boto3\n",
    "\n",
    "from s3fs import S3FileSystem\n",
    "fs = S3FileSystem()\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = '2020-09-01'  #yyyy-mm-dd\n",
    "date_end = '2020-10-01'    #yyyy-mm-dd\n",
    "date_processed_on = '2020-10-14' #yyyy-mm-dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_step_z22 = {\n",
    "    'date_start': date_start, # 'YYYY-MM-DD'\n",
    "    'date_end': date_end, # 'YYYY-MM-DD',\n",
    "    'date_processed_on': date_processed_on, # 'YYYY-MM-DD',\n",
    "    'path_root': 's3://zeta-dc-ml/ai-audiences/',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = PrepUIMatrix(date_start=config_step_z22['date_start'],\n",
    "                    date_end=config_step_z22['date_end'],\n",
    "                    date_processed_on=config_step_z22['date_processed_on'],\n",
    "                    path_root=config_step_z22['path_root'],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30"
     ]
    }
   ],
   "source": [
    "self.generate_list_of_dates_to_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2020, 9, 1, 0, 0), datetime.datetime(2020, 9, 2, 0, 0), datetime.datetime(2020, 9, 3, 0, 0), datetime.datetime(2020, 9, 4, 0, 0), datetime.datetime(2020, 9, 5, 0, 0), datetime.datetime(2020, 9, 6, 0, 0), datetime.datetime(2020, 9, 7, 0, 0), datetime.datetime(2020, 9, 8, 0, 0), datetime.datetime(2020, 9, 9, 0, 0), datetime.datetime(2020, 9, 10, 0, 0), datetime.datetime(2020, 9, 11, 0, 0), datetime.datetime(2020, 9, 12, 0, 0), datetime.datetime(2020, 9, 13, 0, 0), datetime.datetime(2020, 9, 14, 0, 0), datetime.datetime(2020, 9, 15, 0, 0), datetime.datetime(2020, 9, 16, 0, 0), datetime.datetime(2020, 9, 17, 0, 0), datetime.datetime(2020, 9, 18, 0, 0), datetime.datetime(2020, 9, 19, 0, 0), datetime.datetime(2020, 9, 20, 0, 0), datetime.datetime(2020, 9, 21, 0, 0), datetime.datetime(2020, 9, 22, 0, 0), datetime.datetime(2020, 9, 23, 0, 0), datetime.datetime(2020, 9, 24, 0, 0), datetime.datetime(2020, 9, 25, 0, 0), datetime.datetime(2020, 9, 26, 0, 0), datetime.datetime(2020, 9, 27, 0, 0), datetime.datetime(2020, 9, 28, 0, 0), datetime.datetime(2020, 9, 29, 0, 0), datetime.datetime(2020, 9, 30, 0, 0)]"
     ]
    }
   ],
   "source": [
    "self.list_of_dates_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://zeta-dc-ml/ai-audiences/user_activity_daily_sizmek_parquet_UI_COOmatrix/\n",
      "s3://zeta-dc-ml/ai-audiences/user_activity_daily_zync_parquet_UI_COOmatrix/\n",
      "s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/"
     ]
    }
   ],
   "source": [
    "print(self.path_UI_COO_sizmek)\n",
    "print(self.path_UI_COO_zync)\n",
    "print(self.path_UI_COO_disqus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z21_user_item_interactions_sizmek\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z31_user_item_interactions_sizmek\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z41_user_item_interactions_count_sizmek\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z51_item_count_count_sizmek\n",
      "-----------------\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z22_user_item_interactions_zync\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z32_user_item_interactions_zync\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z42_user_item_interactions_count_zync\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z52_item_count_count_zync\n",
      "-----------------\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z23_user_item_interactions_disqus\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z33_user_item_interactions_disqus\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z43_user_item_interactions_count_disqus\n",
      "s3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z53_item_count_count_disqus"
     ]
    }
   ],
   "source": [
    "print(self.path_UI_interactions_sizmek)\n",
    "self.path_UI_interactions_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z31_user_item_interactions_sizmek'\n",
    "self.path_UI_interactions_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z41_user_item_interactions_count_sizmek'\n",
    "self.path_I_count_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z51_item_count_count_sizmek'\n",
    "print(self.path_UI_interactions_sizmek_)\n",
    "print(self.path_UI_interactions_count_sizmek_)\n",
    "print(self.path_I_count_count_sizmek_)\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "print(self.path_UI_interactions_zync)\n",
    "self.path_UI_interactions_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z32_user_item_interactions_zync'\n",
    "self.path_UI_interactions_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z42_user_item_interactions_count_zync'\n",
    "self.path_I_count_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z52_item_count_count_zync'\n",
    "print(self.path_UI_interactions_zync_)\n",
    "print(self.path_UI_interactions_count_zync_)\n",
    "print(self.path_I_count_count_zync_)\n",
    "\n",
    "print('-----------------')\n",
    "\n",
    "print(self.path_UI_interactions_disqus)\n",
    "self.path_UI_interactions_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z33_user_item_interactions_disqus'\n",
    "self.path_UI_interactions_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z43_user_item_interactions_count_disqus'\n",
    "self.path_I_count_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z53_item_count_count_disqus'\n",
    "print(self.path_UI_interactions_disqus_)\n",
    "print(self.path_UI_interactions_count_disqus_)\n",
    "print(self.path_I_count_count_disqus_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path_UI_COO_sizmek to consolidated_UI_COO_sizmek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of buckets in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 209\n",
      "number of buckets that cannot be processed in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 0\n",
      "number of buckets that can be processed in s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/ are 209\n",
      "\n",
      "\n",
      "number of date partitions: 30\n",
      "first path: s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/dt=2020-09-01/*.parquet\n",
      "last path: s3://zeta-dc-ml/ai-audiences/user_activity_daily_disqus_parquet_UI_COOmatrix/dt=2020-09-30/*.parquet"
     ]
    }
   ],
   "source": [
    "# path_list = self.gen_path_list(self.path_UI_COO_sizmek)\n",
    "# path_list = self.gen_path_list(self.path_UI_COO_zync)\n",
    "path_list = self.gen_path_list(self.path_UI_COO_disqus)\n",
    "\n",
    "\n",
    "print(f'number of date partitions: {len(path_list)}')\n",
    "print(f'first path: {path_list[0]}')\n",
    "print(f'last path: {path_list[-1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- zcodes: string (nullable = true)\n",
      " |-- count: long (nullable = true)"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- zcodes: string (nullable = true)\n",
      " |-- count: long (nullable = true)"
     ]
    }
   ],
   "source": [
    "df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.parquet(self.path_UI_interactions_sizmek_)\n",
    "# df.write.parquet(self.path_UI_interactions_zync_)\n",
    "df.write.parquet(self.path_UI_interactions_disqus_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI matrix -> U-I_count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_sizmek_+'/*.parquet')\n",
    "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_zync_+'/*.parquet')\n",
    "df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_disqus_+'/*.parquet')\n",
    "\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of partitions in the dataframe are: 500\n",
      "Shape of the dataframe is 622231127 x 3\n",
      "Schema of the dataframe is:\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- zcodes: string (nullable = true)\n",
      " |-- count: long (nullable = true)"
     ]
    }
   ],
   "source": [
    "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\n",
    "print(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\n",
    "print(f'Schema of the dataframe is:')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107645985"
     ]
    }
   ],
   "source": [
    "# df.select(F.countDistinct(\"user_id\")).show()\n",
    "count_distinct_cookies = (df.select(F.countDistinct(\"user_id\")).collect())[0][0]\n",
    "count_distinct_cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726"
     ]
    }
   ],
   "source": [
    "# df.select(F.countDistinct(\"user_id\")).show()\n",
    "count_distinct_zcodes = (df.select(F.countDistinct(\"zcodes\")).collect())[0][0]\n",
    "count_distinct_zcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupBy(\"user_id\").count().orderBy(col(\"count\").desc()).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- count: long (nullable = false)"
     ]
    }
   ],
   "source": [
    "df = df.groupBy(\"user_id\").count().orderBy(col(\"count\").desc())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- num_zcode: long (nullable = false)"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('count','num_zcode')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.parquet(self.path_UI_interactions_count_sizmek_)\n",
    "# df.write.parquet(self.path_UI_interactions_count_zync_)\n",
    "df.write.parquet(self.path_UI_interactions_count_disqus_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-I_count matrix -> I_count-Count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_sizmek_+'/*.parquet')\n",
    "# df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_zync_+'/*.parquet')\n",
    "df = spark.read.option(\"inferSchema\", True).parquet(self.path_UI_interactions_count_disqus_+'/*.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of partitions in the dataframe are: 407\n",
      "Shape of the dataframe is 107645985 x 2\n",
      "Schema of the dataframe is:\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- num_zcode: long (nullable = true)"
     ]
    }
   ],
   "source": [
    "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\n",
    "print(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\n",
    "print(f'Schema of the dataframe is:')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622231127"
     ]
    }
   ],
   "source": [
    "df.select(F.sum('num_zcode')).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|        user_id|num_zcode|\n",
      "+---------------+---------+\n",
      "| c6pmj1err6dvi7|      208|\n",
      "|c6keckis3f06age|      167|\n",
      "| c5vin6ddk7tbfq|      159|\n",
      "|c7etkq7138lnfjj|      158|\n",
      "| c6k1im741re0it|      156|\n",
      "+---------------+---------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupBy(\"num_zcode\").count().orderBy(col(\"num_zcode\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_zcode: long (nullable = true)\n",
      " |-- count: long (nullable = false)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique num_zcode: 156"
     ]
    }
   ],
   "source": [
    "print(f'number of unique num_zcode: {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|num_zcode|   count|\n",
      "+---------+--------+\n",
      "|        1|11799633|\n",
      "|        2|13505642|\n",
      "|        3|17057432|\n",
      "|        4|13795956|\n",
      "|        5|11962812|\n",
      "+---------+--------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_zcode     count\n",
      "0          1  11799633\n",
      "1          2  13505642\n",
      "2          3  17057432\n",
      "3          4  13795956\n",
      "4          5  11962812"
     ]
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_df.to_csv(self.path_I_count_count_sizmek_+'.csv', header=True, index=False)\n",
    "# pandas_df.to_csv(self.path_I_count_count_zync_+'.csv', header=True, index=False)\n",
    "pandas_df.to_csv(self.path_I_count_count_disqus_+'.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I_count-Count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = pd.read_csv(self.path_I_count_count_sizmek_+'.csv')\n",
    "# pdf = pd.read_csv(self.path_I_count_count_zync_+'.csv')\n",
    "pdf = pd.read_csv(self.path_I_count_count_disqus_+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_zcode     count\n",
      "0          1  11799633\n",
      "1          2  13505642\n",
      "2          3  17057432\n",
      "3          4  13795956\n",
      "4          5  11962812"
     ]
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read email_cookie relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_email_email = 's3://zeta-dcp-prod-private-tables/persistent_identifier/pid_email_links/' + 'dt=2020-10-12/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", True).orc(path_email_email +'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- email_md5: string (nullable = true)\n",
      " |-- link_md5: string (nullable = true)\n",
      " |-- weight: decimal(10,2) (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|           email_md5|            link_md5|weight|\n",
      "+--------------------+--------------------+------+\n",
      "|264976664fc3ba8c2...|bd4b1058985520e14...|  0.60|\n",
      "|e99aa9c2a3d1a509e...|16d70b42251956ae8...|  0.80|\n",
      "|a9ef211e912330863...|61856457c2d5bcf6b...|  0.80|\n",
      "|e4e4e071eb2909727...|14e0556227070d5ae...|  0.80|\n",
      "|96ae9883afd3ea217...|0243273cfc5f3d3e1...|  0.60|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of partitions in the dataframe are: 75690\n",
      "Shape of the dataframe is 156725840876 x 3"
     ]
    }
   ],
   "source": [
    "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\n",
    "print(f'Shape of the dataframe is {df.count()} x {len(df.columns)}')\n",
    "# print(f'Schema of the dataframe is:')\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cookie_email = 's3://zeta-dcp-prod-private-tables/datacloud_cookie_emails_links_export/' + 'dt=2020-10-18/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", True).orc(path_cookie_email +'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cookie: string (nullable = true)\n",
      " |-- email_md5: string (nullable = true)\n",
      " |-- last_connected: timestamp (nullable = true)\n",
      " |-- last_updated: timestamp (nullable = true)\n",
      " |-- pos: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+--------------------+---+\n",
      "|              cookie|           email_md5|     last_connected|        last_updated|pos|\n",
      "+--------------------+--------------------+-------------------+--------------------+---+\n",
      "|zync::0000003c-3b...|a65404227d3459880...|2020-06-26 16:00:32|2020-09-16 00:02:...|  1|\n",
      "|zync::000001ae-65...|7644401120d47b897...|               null|2020-09-16 00:02:...|  1|\n",
      "|zync::000004f1-de...|c4edd56ff9e2e2a23...|2019-09-27 21:43:54|2020-09-16 00:02:...|  1|\n",
      "|zync::000007df-b3...|c774117ef92260e3c...|2020-06-10 02:20:12|2020-09-16 00:02:...|  1|\n",
      "|zync::000007df-b3...|0a04a1e089d58a8da...|2020-05-28 16:27:02|2020-09-16 00:02:...|  2|\n",
      "+--------------------+--------------------+-------------------+--------------------+---+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of partitions in the dataframe are: 6375\n",
      "Shape of the dataframe is 22087657290"
     ]
    }
   ],
   "source": [
    "print(f'No. of partitions in the dataframe are: {df.rdd.getNumPartitions()}')\n",
    "print(f'Shape of the dataframe is {df.count()}') # x {len(df.columns)}')\n",
    "# print(f'Schema of the dataframe is:')\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cookie_cookie = 's3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/' + 'dt=2020-09-24/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"inferSchema\", True).orc(path_cookie_cookie +'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cookie: string (nullable = true)\n",
      " |-- relation: string (nullable = true)\n",
      " |-- last_connected: timestamp (nullable = true)\n",
      " |-- last_updated: timestamp (nullable = true)\n",
      " |-- pos: integer (nullable = true)\n",
      " |-- dt: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+--------------------+---+----------+\n",
      "|              cookie|            relation|last_connected|        last_updated|pos|        dt|\n",
      "+--------------------+--------------------+--------------+--------------------+---+----------+\n",
      "|zync::69c55eb9-76...|sizmek::158224121...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n",
      "|zync::69c55eb9-76...|zync::69c55eb9-76...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n",
      "|sizmek::197630618...|disqus::c819ns0h3...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n",
      "|sizmek::197630618...|sizmek::197630618...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n",
      "|sizmek::165092110...|sizmek::165092110...|          null|2020-09-14 07:10:...|  1|2020-09-24|\n",
      "+--------------------+--------------------+--------------+--------------------+---+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepUIMatrix:\n",
    "\n",
    "    def __init__(self,\n",
    "                 date_start, # str in format YYYY-MM-DD\n",
    "                 date_end, # str in format YYYY-MM-DD\n",
    "                 date_processed_on, # str in format YYYY-MM-DD\n",
    "                 path_root='s3://zeta-dc-ml/ai-audiences/',\n",
    "                 ):\n",
    "\n",
    "        self.date_start = date_start\n",
    "        self.date_end = date_end\n",
    "        self.date_processed_on = date_processed_on\n",
    "\n",
    "        self.path_root = path_root\n",
    "\n",
    "        self.path_root_modeling = self.path_root + 'modeling/dt=' + date_processed_on + '/'\n",
    "\n",
    "        self.path_UI_COO_sizmek = self.path_root + 'user_activity_daily_sizmek_parquet_UI_COOmatrix/'\n",
    "        self.path_UI_COO_zync = self.path_root + 'user_activity_daily_zync_parquet_UI_COOmatrix/'\n",
    "        self.path_UI_COO_disqus = self.path_root + 'user_activity_daily_disqus_parquet_UI_COOmatrix/'\n",
    "\n",
    "        self.path_disqus_to_sizmek = self.path_root + 'datacloud_cookie_cookie_relations/disqus_to_sizmek/'\n",
    "        self.path_zync_to_sizmek = self.path_root + 'datacloud_cookie_cookie_relations/zync_to_sizmek/'\n",
    "\n",
    "        self.path_UI_interactions_sizmek = self.path_root_modeling + 'z21_user_item_interactions_sizmek'\n",
    "        self.path_UI_interactions_zync = self.path_root_modeling + 'z22_user_item_interactions_zync'\n",
    "        self.path_UI_interactions_disqus = self.path_root_modeling + 'z23_user_item_interactions_disqus'\n",
    "\n",
    "        self.path_UI_interactions_final = self.path_root_modeling + 'z01_user_item_interactions'\n",
    "\n",
    "        self.list_of_dates_to_process = None\n",
    "\n",
    "        self.date_processed_latest_zync_to_sizmek = None\n",
    "        self.date_processed_latest_disqus_to_sizmek = None\n",
    "\n",
    "    def generate_list_of_dates_to_process(self):\n",
    "        start = datetime.datetime.strptime(self.date_start, '%Y-%m-%d')\n",
    "        end = datetime.datetime.strptime(self.date_end, '%Y-%m-%d')\n",
    "        self.list_of_dates_to_process = [start + datetime.timedelta(days=x) for x in range(0, (end - start).days)]\n",
    "\n",
    "        print(len(self.list_of_dates_to_process))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_list_of_all_dates_present(bucket, prefix):\n",
    "\n",
    "        s3 = boto3.client(\"s3\")\n",
    "        all_objects = s3.list_objects(Bucket=bucket,\n",
    "                                      Prefix=prefix,\n",
    "                                      Delimiter='/')\n",
    "\n",
    "        list_date_buckets = []\n",
    "        for o in all_objects.get('CommonPrefixes'):\n",
    "            list_date_buckets.append(o.get('Prefix'))\n",
    "        #     print(o.get('Prefix'))\n",
    "\n",
    "        print('number of buckets in s3://{}/{} are {}'.format(bucket, prefix, len(list_date_buckets)))\n",
    "\n",
    "        list_dates_present = [el.split('/')[-2].split('=')[-1] for el in list_date_buckets]\n",
    "\n",
    "        list_dates_that_can_be_processed = []\n",
    "\n",
    "        count = 0\n",
    "        for el in list_dates_present:\n",
    "            try:\n",
    "                list_dates_that_can_be_processed.append(datetime.datetime.strptime(el, '%Y-%m-%d'))\n",
    "            except:\n",
    "                count = count + 1\n",
    "                print('date partition that cannot be processed: {}'.format(el))\n",
    "\n",
    "        print('number of buckets that cannot be processed in s3://{}/{} are {}'.format(bucket, prefix, count))\n",
    "        print('number of buckets that can be processed in s3://{}/{} are {}'.format(bucket, prefix, len(\n",
    "            list_dates_that_can_be_processed)))\n",
    "\n",
    "        list_dates_that_can_be_processed.sort()\n",
    "\n",
    "        return list_dates_that_can_be_processed\n",
    "\n",
    "    def gen_path_list(self, path_UI_COO):\n",
    "\n",
    "        # The purpose of this function is to find the intersection of the {dates requested} with {dates present in data}\n",
    "        # This will be applied to all three tables individually\n",
    "        # Some sources might have missing dates\n",
    "\n",
    "        bucket = path_UI_COO.split('/')[2]\n",
    "        rest_of_path = os.path.join(*(path_UI_COO.split('/')[3:]))\n",
    "\n",
    "        list_of_dates_present = self.get_list_of_all_dates_present(bucket=bucket,\n",
    "                                                                   prefix=rest_of_path)\n",
    "\n",
    "        list_of_dates_available = list(set(self.list_of_dates_to_process).intersection(list_of_dates_present))\n",
    "        list_of_dates_available.sort()\n",
    "\n",
    "        print(''.format(len(list_of_dates_present)))\n",
    "        print(''.format(len(list_of_dates_available)))\n",
    "\n",
    "        path_list = [path_UI_COO + 'dt=' + date.strftime('%Y-%m-%d') + '/*.parquet' for date in list_of_dates_available]\n",
    "\n",
    "        return path_list\n",
    "\n",
    "    def get_latest_date_partition(self, path):\n",
    "\n",
    "        bucket = path.split('/')[2]\n",
    "        rest_of_path = os.path.join(*(path.split('/')[3:]))\n",
    "\n",
    "        list_of_all_dates_that_can_be_processed = self.get_list_of_all_dates_present(bucket=bucket,\n",
    "                                                                                     prefix=rest_of_path)\n",
    "        return list_of_all_dates_that_can_be_processed[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    def generate_sizmek_ui_matrix(self):\n",
    "        path_list = self.gen_path_list(self.path_UI_COO_sizmek)\n",
    "        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n",
    "        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n",
    "        df.write.parquet(self.path_UI_interactions_sizmek)\n",
    "\n",
    "    def generate_disqus_ui_matrix(self):\n",
    "        # Disqus UI Matrix -> Disqus_Sizmek UI Matrix\n",
    "\n",
    "        work_on_date_partition = self.get_latest_date_partition(self.path_zync_to_sizmek)\n",
    "\n",
    "        # Read the latest Disqus to Sizmek Cookie Mapping\n",
    "        df_disqus_to_sizmek = spark.read.option(\"inferSchema\", True).parquet(self.path_disqus_to_sizmek + 'dt=' + work_on_date_partition + '/*.parquet')\n",
    "\n",
    "        path_list = self.gen_path_list(self.path_UI_COO_disqus)\n",
    "\n",
    "        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n",
    "\n",
    "        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n",
    "        df = df.join(df_disqus_to_sizmek, df.user_id == df_disqus_to_sizmek.cookie_disqus, 'inner')\n",
    "        df = df.select([explode(df.cookie_sizmek).alias('user_id'), 'zcodes', 'count'])\n",
    "\n",
    "        df.write.parquet(self.path_UI_interactions_disqus)\n",
    "\n",
    "    def generate_zync_ui_matrix(self):\n",
    "        # Zync UI Matrix -> Zync_Sizmek UI Matrix\n",
    "\n",
    "        work_on_date_partition = self.get_latest_date_partition(self.path_zync_to_sizmek)\n",
    "\n",
    "        # Read the latest Zync to Sizmek Cookie Mapping\n",
    "        df_zync_to_sizmek = spark.read.option(\"inferSchema\", True).parquet(self.path_zync_to_sizmek + 'dt=' + work_on_date_partition + '/*.parquet')\n",
    "\n",
    "        path_list = self.gen_path_list(self.path_UI_COO_zync)\n",
    "\n",
    "        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n",
    "\n",
    "        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n",
    "        df = df.join(df_zync_to_sizmek, df.user_id == df_zync_to_sizmek.cookie_zync, 'inner')\n",
    "        df = df.select([explode(df.cookie_sizmek).alias('user_id'), 'zcodes', 'count'])\n",
    "\n",
    "        df.write.parquet(self.path_UI_interactions_zync)\n",
    "\n",
    "    def generate_final_ui_matrix(self):\n",
    "\n",
    "        # Sizmek_UI_Final = Sizmek_UI + Zync_Sizmek_UI + Disqus_Sizmek_UI\n",
    "\n",
    "        path_list = [self.path_UI_interactions_sizmek + '/*.parquet',\n",
    "                     self.path_UI_interactions_zync + '/*.parquet',\n",
    "                     self.path_UI_interactions_disqus + '/*.parquet']\n",
    "\n",
    "        df = spark.read.option(\"inferSchema\", True).parquet(*path_list)\n",
    "\n",
    "        df = df.groupby('user_id', 'zcodes').agg(F.sum('count').alias('count'))\n",
    "\n",
    "        df.write.parquet(self.path_UI_interactions_final)\n",
    "\n",
    "#     def run_step(self):\n",
    "#         self.generate_list_of_dates_to_process()\n",
    "#         self.generate_sizmek_ui_matrix()\n",
    "#         self.generate_disqus_ui_matrix()\n",
    "#         self.generate_zync_ui_matrix()\n",
    "#         self.generate_final_ui_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
