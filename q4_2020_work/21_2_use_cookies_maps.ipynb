{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "pass", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1605607978346_0004</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-32-23-70.ec2.internal:20888/proxy/application_1605607978346_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-32-22-254.ec2.internal:8042/node/containerlogs/container_1605607978346_0004_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n# %load_ext autoreload\n\n# %autoreload 2\n\n# %matplotlib inline", "execution_count": 2, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport dask.dataframe as dd\n\n# import matplotlib.pyplot as plt\n\n# from tqdm import tqdm\n# tqdm.pandas() # use progress_apply instead of apply\n\nfrom dask.diagnostics import ProgressBar\nProgressBar().register()\n", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import logging\n\nimport os\nimport sys\nimport json\n# from pyspark.sql import SparkSession\n\nfrom datetime import datetime\n\nimport boto3\n\nfrom s3fs import S3FileSystem\nfs = S3FileSystem()\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import explode, col", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": 5, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class PrepUIMatrix:\n    def __init__(self):\n        pass\n    def func(self):\n        pass\n\nself = PrepUIMatrix()", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "self.path_cookie_cookie_staging = 's3://zeta-dc-ml/ai-audiences/datacloud_cookie_cookie_relations/cookie_cookie_staging/dt=2020-11-16'\n\n", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "self.path_UI_interactions_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z31_user_item_interactions_sizmek'\nself.path_UI_interactions_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z41_user_item_interactions_count_sizmek'\nself.path_I_count_count_sizmek_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z51_item_count_count_sizmek'\n\nself.path_UI_interactions_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z32_user_item_interactions_zync'\nself.path_UI_interactions_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z42_user_item_interactions_count_zync'\nself.path_I_count_count_zync_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z52_item_count_count_zync'\n\nself.path_UI_interactions_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z33_user_item_interactions_disqus'\nself.path_UI_interactions_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z43_user_item_interactions_count_disqus'\nself.path_I_count_count_disqus_ = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z53_item_count_count_disqus'\n\n", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df = spark.read.option(\"inferSchema\", True).parquet(self.path_cookie_cookie_staging + '/*parquet')\ndf.printSchema()\ndf.show(n=4)\n", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "root\n |-- source: string (nullable = true)\n |-- cookie_source: string (nullable = true)\n |-- destination: string (nullable = true)\n |-- cookie_destination: string (nullable = true)\n |-- last_updated: timestamp (nullable = true)\n\n+--------+--------------------+-----------+--------------------+-------------------+\n|  source|       cookie_source|destination|  cookie_destination|       last_updated|\n+--------+--------------------+-----------+--------------------+-------------------+\n|33across|/yUFtV9N+3v/i2F4A...|     sizmek| 2810035062355267748|2020-09-15 00:00:00|\n|33across|/yUFtV9N+rL/i2F4A...|       zync|db9cd184-149a-4f6...|2020-09-09 20:00:00|\n|33across|/yUFtV9N2tL/i2F4A...|       zync|ff74ac59-285a-4b0...|2020-09-07 21:00:00|\n|33across|/yUFtV9N9H7/i2F4A...|       zync|b1c47d46-ee23-46b...|2020-09-07 06:00:00|\n+--------+--------------------+-----------+--------------------+-------------------+\nonly showing top 4 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.source == 'sizmek').count()", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "20900010516", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.source == 'zync').count()", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "27366652183", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.source == 'disqus').count()", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "12755004399", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.destination == 'disqus').count()", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "12126421925", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.destination == 'zync').count()", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "25353426842", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter(df.destination == 'sizmek').count()", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "23146752456", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'disqus') & (df.destination == 'sizmek')).count()", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "3372866566", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'sizmek') & (df.destination == 'disqus')).count()", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "2667247165", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'zync') & (df.destination == 'sizmek')).count()", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "12084795314", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'sizmek') & (df.destination == 'zync')).count()", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "10780176468", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'disqus') & (df.destination == 'zync')).count()", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "3191754906", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "df.filter((df.source == 'zync') & (df.destination == 'disqus')).count()", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "3397344784", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df.printSchema()", "execution_count": 115, "outputs": [{"output_type": "stream", "text": "root\n |-- source: string (nullable = true)\n |-- cookie_source: string (nullable = true)\n |-- destination: string (nullable = true)\n |-- cookie_destination: string (nullable = true)\n |-- last_updated: timestamp (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_zync_to_sizmek_1 = df.filter((df.source == 'zync') & (df.destination == 'sizmek'))\n\ndf_zync_to_sizmek_1 = df_zync_to_sizmek_1.selectExpr('cookie_source as cookie_zync',\n                                                     'cookie_destination as cookie_sizmek')\n\ndf_zync_to_sizmek_1.printSchema()\n", "execution_count": 116, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_zync: string (nullable = true)\n |-- cookie_sizmek: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_zync_to_sizmek_2 = df.filter((df.source == 'sizmek') & (df.destination == 'zync'))\n\ndf_zync_to_sizmek_2 = df_zync_to_sizmek_2.selectExpr('cookie_source as cookie_sizmek',\n                                                     'cookie_destination as cookie_zync'\n                                                     )\ndf_zync_to_sizmek_2.printSchema()", "execution_count": 117, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_sizmek: string (nullable = true)\n |-- cookie_zync: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_zync_to_sizmek = df_zync_to_sizmek_1.union(df_zync_to_sizmek_2)\ndf_zync_to_sizmek.printSchema()", "execution_count": 118, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_zync: string (nullable = true)\n |-- cookie_sizmek: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_zync_to_sizmek = df_zync_to_sizmek.drop_duplicates()\n# df_zync_to_sizmek.count()\n\n# df_zync_to_sizmek = (df_zync_to_sizmek\n#                        .groupBy('cookie_zync')\n#                        .agg(F.collect_set('cookie_dest').alias('cookie_sizmek'))\n#                       )\n\n\n", "execution_count": 119, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_zync_to_sizmek.printSchema()", "execution_count": 120, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_zync: string (nullable = true)\n |-- cookie_sizmek: string (nullable = true)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp = df_zync_to_sizmek.groupBy(\"cookie_sizmek\").count().orderBy(col(\"count\").desc())", "execution_count": 121, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp.printSchema()", "execution_count": 122, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_sizmek: string (nullable = true)\n |-- count: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp = df_temp.withColumnRenamed('count','num_cookies')", "execution_count": 123, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp.printSchema()", "execution_count": 124, "outputs": [{"output_type": "stream", "text": "root\n |-- cookie_sizmek: string (nullable = true)\n |-- num_cookies: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp = df_temp.groupBy(\"num_cookies\").count().orderBy(col(\"num_cookies\").desc())", "execution_count": 125, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "df_temp.printSchema()", "execution_count": 126, "outputs": [{"output_type": "stream", "text": "root\n |-- num_cookies: long (nullable = false)\n |-- count: long (nullable = false)", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pandas_df = df_temp.toPandas()", "execution_count": 127, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pandas_df.head()", "execution_count": 128, "outputs": [{"output_type": "stream", "text": "   num_cookies  count\n0         5113      1\n1         4168      1\n2         4075      1\n3         1525      1\n4         1349      1", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "path = 's3://zeta-dc-ml/ai-audiences/modeling/dt=2020-10-14/z102_sizmek_zync_count.csv'\npandas_df.to_csv(path, header=True, index=False)", "execution_count": 129, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "self.get_list_dates_that_can_be_processed()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "number of buckets in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 132\ndatacloud_cookie_cookies_relations_links_export/dt=0-sample-2020-06-19/\ndate partition that cannot be processed: 0-sample-2020-06-19\ndate partition that cannot be processed: 2020-06-02-sample\ndate partition that cannot be processed: backfill-scylla-till-09-17\ndate partition that cannot be processed: bkp_2020-10-08\ndate partition that cannot be processed: final-test-2020-11-11\ndate partition that cannot be processed: sample-backfill-scylla-till-09-17\ndate partition that cannot be processed: test-2020-06-28\nnumber of buckets that cannot be processed in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 7\nnumber of buckets that can be processed in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 125", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "self.prep_cookie_cookie_map_table()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "number of buckets in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 133\ndatacloud_cookie_cookies_relations_links_export/dt=0-sample-2020-06-19/\ndate partition that cannot be processed: 0-sample-2020-06-19\ndate partition that cannot be processed: 2020-06-02-sample\ndate partition that cannot be processed: backfill-scylla-till-09-17\ndate partition that cannot be processed: bkp_2020-10-08\ndate partition that cannot be processed: final-test-2020-11-11\ndate partition that cannot be processed: sample-backfill-scylla-till-09-17\ndate partition that cannot be processed: test-2020-06-28\nnumber of buckets that cannot be processed in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 7\nnumber of buckets that can be processed in s3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/ are 126\nLatest Date to process is 2020-11-16\nSource read successful for date: 2020-11-16\nprocessed cookie_cookie_mappings with latest date processed: 2020-11-16", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import logging\n\nimport os\nimport sys\nimport json\nfrom pyspark.sql import SparkSession\n\nimport boto3\nfrom datetime import datetime\nfrom urllib.parse import urlparse\n\n# https://stackoverflow.com/questions/39235704/split-spark-dataframe-string-column-into-multiple-columns\nfrom pyspark.sql.functions import split\nfrom pyspark.sql.functions import collect_set, collect_list # collect_set eliminates duplicates, collect_list does not", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "PATH_ROOT = 's3://zeta-dc-ml/ai-audiences/'\nPATH_COOKIE_COOKIES_RELATIONS = 's3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/'\n\n\nclass CookieMapUpdate:\n\n    def __init__(self,\n                 path_root=PATH_ROOT,\n                 path_cookie_cookies_relations=PATH_COOKIE_COOKIES_RELATIONS,\n                 ):\n\n        self.path_root = path_root\n        self.path_cookie_relations_dest_root = self.path_root + 'datacloud_cookie_cookie_relations/'\n        self.path_cookie_cookie_staging = self.path_cookie_relations_dest_root + 'cookie_cookie_staging/'\n        self.path_disqus_to_sizmek = self.path_cookie_relations_dest_root + 'disqus_to_sizmek/'\n        self.path_zync_to_sizmek = self.path_cookie_relations_dest_root + 'zync_to_sizmek/'\n\n        self.path_cookie_cookies_relations = path_cookie_cookies_relations\n\n        self.list_of_all_dates_that_can_be_processed = None\n        self.date_processed_latest = None\n        self.date_processed_latest_counter = 0\n\n    @staticmethod\n    def get_list_of_all_dates_present(bucket, prefix):\n        \n        s3 = boto3.client(\"s3\")\n        all_objects = s3.list_objects(Bucket=bucket,\n                                      Prefix=prefix,\n                                      Delimiter='/')\n\n        list_date_buckets = []\n        for o in all_objects.get('CommonPrefixes'):\n            list_date_buckets.append(o.get('Prefix'))\n\n        print(f'number of buckets in s3://{bucket}/{prefix} are {len(list_date_buckets)}')\n        \n        print(list_date_buckets[0])\n\n        list_dates_present = [el.split('/')[-2].split('=')[-1] for el in list_date_buckets]\n\n        list_dates_that_can_be_processed = []\n\n        count = 0\n        for el in list_dates_present:\n            try:\n                list_dates_that_can_be_processed.append(datetime.strptime(el, '%Y-%m-%d'))\n            except:\n                count = count + 1\n                print(f'date partition that cannot be processed: {el}')\n\n        print(f'number of buckets that cannot be processed in s3://{bucket}/{prefix} are {count}')\n        print(f'number of buckets that can be processed in s3://{bucket}/{prefix} are {len(list_dates_that_can_be_processed)}')\n\n        list_dates_that_can_be_processed.sort()\n\n        return list_dates_that_can_be_processed\n\n    def get_list_dates_that_can_be_processed(self):\n\n        parsed_url = urlparse(self.path_cookie_cookies_relations, allow_fragments=False)\n\n        bucket = parsed_url.netloc\n        rest_of_path = parsed_url.path.lstrip('/')\n\n        self.list_of_all_dates_that_can_be_processed = self.get_list_of_all_dates_present(bucket=bucket,\n                                                                                          prefix=rest_of_path)\n\n    def get_date_processed_latest(self):\n\n        self.date_processed_latest = self.list_of_all_dates_that_can_be_processed[-1 - self.date_processed_latest_counter].strftime('%Y-%m-%d')\n        print(f'Latest Date to process is {self.date_processed_latest}')\n\n    def prep_cookie_cookie_map_table(self):\n\n        # Read from the latest, if the latest fails, read from the second to latest, else keep going back upto 10? days\n        num_read_attempts = 10\n        self.get_list_dates_that_can_be_processed()\n        for i in range(num_read_attempts):\n            try:\n                self.get_date_processed_latest()\n                df = (spark.read.option(\"inferSchema\", True)\n                      .orc(os.path.join(self.path_cookie_cookies_relations,\n                                        f'dt={self.date_processed_latest}',\n                                        '*'\n                                        )\n                           )\n                      )\n                print(f'Source read successful for date: {self.date_processed_latest}')\n                break\n            except:\n                # TODO: Alert AI-ML team as this could mean a change in table/schema\n                print(f'Source read failed for date: {self.date_processed_latest}')\n                self.date_processed_latest_counter = self.date_processed_latest_counter + 1\n\n        if self.date_processed_latest_counter == 10:\n            print('Cookie - Cookie Mapping table has issues')\n            return None\n\n        split_col = split(df['cookie'], '::')\n        df = df.withColumn('source', split_col.getItem(0))\n        df = df.withColumn('cookie_source', split_col.getItem(1))\n\n        split_col = split(df['relation'], '::')\n        df = df.withColumn('destination', split_col.getItem(0))\n        df = df.withColumn('cookie_destination', split_col.getItem(1))\n\n        df = df.select(df['source'], df['cookie_source'], df['destination'], df['cookie_destination'], df['last_updated'])\n\n        try:\n            df.write.parquet(os.path.join(self.path_cookie_cookie_staging,\n                                          f'dt={self.date_processed_latest}'\n                                          )\n                             )\n            print(f'processed cookie_cookie_mappings with latest date processed: {self.date_processed_latest}')\n        except:\n            print(f'data of cookie_cookie_mappings for date {self.date_processed_latest} might already exist')\n\n    def prep_disqus_sizmek_map_table(self):\n\n        bucket = self.path_cookie_cookie_staging.split('/')[2]\n        rest_of_path = os.path.join(*(self.path_cookie_cookie_staging.split('/')[3:]))\n\n        temp_list_of_dates = self.get_list_of_all_dates_present(bucket=bucket,\n                                                                prefix=rest_of_path)\n        date_processed_latest_ = temp_list_of_dates[-1].strftime('%Y-%m-%d')\n\n        df = (spark.read.option(\"inferSchema\", True)\n              .parquet(os.path.join(self.path_cookie_cookie_staging,\n                                    f'dt={date_processed_latest_}',\n                                    '*parquet')\n                       )\n              )\n\n        df_disqus_to_sizmek = df.filter((df.source == 'disqus') & (df.destination == 'sizmek'))\n\n        df_disqus_to_sizmek = df_disqus_to_sizmek.selectExpr('cookie_source as cookie_disqus',\n                                                             'cookie_destination as cookie_dest')\n        df_disqus_to_sizmek = df_disqus_to_sizmek.drop_duplicates()\n\n        df_disqus_to_sizmek = (df_disqus_to_sizmek\n                               .groupBy('cookie_disqus')\n                               .agg(collect_set('cookie_dest').alias('cookie_sizmek'))\n                               )\n        try:\n            df_disqus_to_sizmek.write.parquet(os.path.join(self.path_disqus_to_sizmek,\n                                                           f'dt={date_processed_latest_}'\n                                                           )\n                                              )\n            print(f'processed disqus_to_sizmek_cookie_mappings with latest date processed: {date_processed_latest_}')\n        except:\n            print(f'data of disqus_to_sizmek for date {date_processed_latest_} might already exist')\n\n    def prep_zync_sizmek_map_table(self):\n\n        bucket = self.path_cookie_cookie_staging.split('/')[2]\n        rest_of_path = os.path.join(*(self.path_cookie_cookie_staging.split('/')[3:]))\n\n        temp_list_of_dates = self.get_list_of_all_dates_present(bucket=bucket,\n                                                                prefix=rest_of_path)\n        date_processed_latest_ = temp_list_of_dates[-1].strftime('%Y-%m-%d')\n\n        df = (spark.read.option(\"inferSchema\", True)\n              .parquet(os.path.join(self.path_cookie_cookie_staging,\n                                    f'dt={date_processed_latest_}',\n                                    '*.parquet')\n                       )\n              )\n\n        df_zync_to_sizmek = df.filter((df.source == 'zync') & (df.destination == 'sizmek'))\n\n        df_zync_to_sizmek = df_zync_to_sizmek.selectExpr('cookie_source as cookie_zync',\n                                                         'cookie_destination as cookie_dest')\n        df_zync_to_sizmek = df_zync_to_sizmek.drop_duplicates()\n\n        df_zync_to_sizmek = (df_zync_to_sizmek\n                             .groupBy('cookie_zync')\n                             .agg(collect_set('cookie_dest').alias('cookie_sizmek'))\n                             )\n\n        try:\n            df_zync_to_sizmek.write.parquet(os.path.join(self.path_zync_to_sizmek,\n                                                         f'dt={date_processed_latest_}'\n                                                         )\n                                            )\n            print(f'processed zync_to_sizmek_cookie_mappings with latest date processed: {date_processed_latest_}')\n        except:\n            print(f'data of zync_to_sizmek for date {date_processed_latest_} might already exist')\n\n    def run_step(self):\n        try:\n            self.prep_cookie_cookie_map_table()\n        except:\n            # TODO: Alert AI-ML team about a potential change in table/schema\n            print('difficulty reading cookie cookie mapping table')\n        self.prep_disqus_sizmek_map_table()\n        self.prep_zync_sizmek_map_table()\n        print('finished step CookieMapUpdate')\n", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "config_step_z12 = {\n    'path_root': 's3://zeta-dc-ml/ai-audiences/',\n    'path_cookie_cookies_relations': 's3://zeta-dcp-prod-private-tables/datacloud_cookie_cookies_relations_links_export/',\n}\n", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "self = CookieMapUpdate(path_root=config_step_z12['path_root'],\n                                         path_cookie_cookies_relations=config_step_z12['path_cookie_cookies_relations'],\n                                        )\n    ", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pyspark3kernel", "display_name": "PySpark3", "language": ""}, "language_info": {"name": "pyspark3", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 2}