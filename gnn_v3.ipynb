{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed216c3c-3c61-4539-98e7-1873002d0921",
   "metadata": {},
   "source": [
    "# Graph Matching Consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d80be-11f3-4524-b8e2-7e01866e1dc5",
   "metadata": {},
   "source": [
    "## Initialize and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bf27d8-6641-4b29-9686-0c48cb6bdcc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T20:50:00.375027Z",
     "iopub.status.busy": "2021-08-18T20:50:00.374666Z",
     "iopub.status.idle": "2021-08-18T20:50:01.639244Z",
     "shell.execute_reply": "2021-08-18T20:50:01.638592Z",
     "shell.execute_reply.started": "2021-08-18T20:50:00.374977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Callable, List, Dict, Tuple\n",
    "import os\n",
    "\n",
    "import dgmc\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import funcs\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c6389-151c-47ff-b6f0-392133121eba",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0089ec15-7941-40c2-aafc-2337f884427e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T20:50:03.104162Z",
     "iopub.status.busy": "2021-08-18T20:50:03.103904Z",
     "iopub.status.idle": "2021-08-18T20:50:03.123261Z",
     "shell.execute_reply": "2021-08-18T20:50:03.122559Z",
     "shell.execute_reply.started": "2021-08-18T20:50:03.104143Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(pl.LightningModule):\n",
    "    def __init__(self, dataset):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "        #self.conv1 = GCNConv(dataset.num_features, 4)\n",
    "        self.conv1 = GCNConv(596, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = Linear(2, dataset.num_classes)\n",
    "\n",
    "        self.in_channels = dataset.num_features\n",
    "        self.out_channels = dataset.num_classes\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        print(\"x: \", x.shape)\n",
    "        print(\"edge_index: \", edge_index.shape)\n",
    "        #print(\"self: \", self.)\n",
    "        # mat1 and mat2 shapes cannot be multiplied (10000x9070 and 596x4)\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54705da4-5bce-4515-a23a-16e9742f68d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T20:50:16.405052Z",
     "iopub.status.busy": "2021-08-18T20:50:16.404532Z",
     "iopub.status.idle": "2021-08-18T20:50:17.979010Z",
     "shell.execute_reply": "2021-08-18T20:50:17.978359Z",
     "shell.execute_reply.started": "2021-08-18T20:50:16.405031Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drose/github/GNN-playground/funcs.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[column] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizmek: (nodes:10,000, edges:2,212,814)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drose/github/GNN-playground/funcs.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  features[column] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zync: (nodes:10,000, edges:110,023)\n"
     ]
    }
   ],
   "source": [
    "sizmek_path = \"data/sizmek_bidstream_raw_20210625_10k.csv\"\n",
    "zync_path = \"data/zync_session_tracking_orc_20210625_10k.csv\"\n",
    "\n",
    "sizmek_cols = [\"account_id\", \"referrer_url\", \"city_code\",\n",
    "               \"state_code\", \"dma_code\", \"country_code\"]\n",
    "zync_cols = [\"client\", \"user_agent_platform\",\n",
    "             \"user_agent_language\", \"user_agent_browser\"]\n",
    "\n",
    "# Load and Create Sizmek Data\n",
    "sizmek_data = funcs.ZetaData(sizmek_path, \"url\", \"zeta_user_id\", sizmek_cols, parse_url=False)\n",
    "sizmek_model = GCN(sizmek_data)\n",
    "\n",
    "# Load and Create Zync Data\n",
    "zync_data = funcs.ZetaData(zync_path, \"referrer\", \"client_id\", zync_cols, parse_url=False, expand_x=596)\n",
    "zync_model = GCN(zync_data)\n",
    "\n",
    "\n",
    "print(f\"Sizmek: (nodes:{sizmek_data.node_count:,}, edges:{sizmek_data.edge_count:,})\")\n",
    "print(f\"Zync: (nodes:{zync_data.node_count:,}, edges:{zync_data.edge_count:,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193c87fe-b071-4b7c-b853-ed4052288aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T20:50:22.281321Z",
     "iopub.status.busy": "2021-08-18T20:50:22.280985Z",
     "iopub.status.idle": "2021-08-18T20:50:22.357990Z",
     "shell.execute_reply": "2021-08-18T20:50:22.357313Z",
     "shell.execute_reply.started": "2021-08-18T20:50:22.281305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "psi_1 = dgmc.models.GIN(\n",
    "    in_channels=sizmek_data.num_features,\n",
    "    out_channels=256,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "psi_2 = dgmc.models.GIN(\n",
    "    in_channels=32,\n",
    "    out_channels=32,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "model = dgmc.DGMC(psi_1, psi_2, num_steps=None, k=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Create fake labels for testing\n",
    "y_1 = torch.tensor([range(0,2000)])[0]\n",
    "y_2 = torch.tensor([range(0,2000)])[0]\n",
    "train_y = torch.stack([y_1, y_2], dim=0)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    _, out = model.forward(\n",
    "        x_s=sizmek_data.x,\n",
    "        edge_index_s=sizmek_data.edge_index,\n",
    "        edge_attr_s=None,\n",
    "        batch_s=None,\n",
    "        x_t=zync_data.x,\n",
    "        edge_index_t=zync_data.edge_index,\n",
    "        edge_attr_t=None,\n",
    "        batch_t=None,\n",
    "        y=None\n",
    "    )\n",
    "    loss = model.loss(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    _, out = model.forward(\n",
    "        x_s=sizmek_data.x,\n",
    "        edge_index_s=sizmek_data.edge_index,\n",
    "        edge_attr_s=None,\n",
    "        batch_s=None,\n",
    "        x_t=zync_data.x,\n",
    "        edge_index_t=zync_data.edge_index,\n",
    "        edge_attr_t=None,\n",
    "        batch_t=None,\n",
    "        y=None\n",
    "    )\n",
    "\n",
    "    hits1 = model.acc(out, train_y)\n",
    "    hits10 = model.hits_at_k(10, out, train_y)\n",
    "\n",
    "    return hits1, hits10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b74621-7466-4911-9474-8b339aa38718",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-08-18T21:40:16.210551Z",
     "iopub.status.busy": "2021-08-18T21:40:16.209970Z",
     "iopub.status.idle": "2021-08-18T21:40:59.242222Z",
     "shell.execute_reply": "2021-08-18T21:40:59.241457Z",
     "shell.execute_reply.started": "2021-08-18T21:40:16.210532Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize initial feature matching...\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drose/github/.envs/.gmc/lib/python3.8/site-packages/pandas/core/frame.py:3640: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = value\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5783/1855559325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#if epoch % 10 == 0 or epoch > 100:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5783/1355101375.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/.envs/.gmc/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/.envs/.gmc/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "print('Optimize initial feature matching...')\n",
    "model.num_steps = 0\n",
    "for epoch in range(1, 201):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    if epoch == 5:\n",
    "        print('Refine correspondence matrix...')\n",
    "        model.num_steps = 3\n",
    "        model.detach = True\n",
    "\n",
    "    loss = train()\n",
    "\n",
    "    #if epoch % 10 == 0 or epoch > 100:\n",
    "    if True:\n",
    "        hits1, hits10 = test()\n",
    "        print((f'{epoch:03d}: Loss: {loss:.4f}, Hits@1: {hits1:.4f}, '\n",
    "               f'Hits@10: {hits10:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce6ef5-e263-4324-8202-04cd15a13f59",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67c172-3ae2-4597-905f-03e75f5eb346",
   "metadata": {},
   "source": [
    "# Sratch Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820e11a-3d7e-4d8f-beab-7b3567c46a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDGMC(dgmc.DGMC):\n",
    "    def __init__(self, psi_1, psi_2, num_steps=None, k=10):\n",
    "        super(LightningDGMC, self).__init__(psi_1, psi_2, num_steps)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        _, out = self.forward(\n",
    "            x_s=train_batch[\"sizmek\"].x,\n",
    "            edge_index_s=train_batch[\"sizmek\"].edge_index,\n",
    "            edge_attr_s=None,\n",
    "            batch_s=None,\n",
    "            x_t=train_batch[\"zync\"].x,\n",
    "            edge_index_t=train_batch[\"zync\"].edge_index,\n",
    "            edge_attr_t=None,\n",
    "            batch_t=None,\n",
    "            y=None\n",
    "        )\n",
    "        loss = model.loss(out, train_batch.train_y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch):\n",
    "        _, out = self.forward(\n",
    "            x_s=val_batch[\"sizmek\"].x,\n",
    "            edge_index_s=val_batch[\"sizmek\"].edge_index,\n",
    "            edge_attr_s=None,\n",
    "            batch_s=None,\n",
    "            x_t=val_batch[\"zync\"].x,\n",
    "            edge_index_t=val_batch[\"zync\"].edge_index,\n",
    "            edge_attr_t=None,\n",
    "            batch_t=None,\n",
    "            y=None\n",
    "        )\n",
    "\n",
    "        hits1 = self.acc(out, val_batch[\"val_y\"])\n",
    "        hits10 = self.hits_at_k(10, out, val_batch[\"val_y\"])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cb957-78bc-4622-97c5-104e5ecff92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_1 = torch.tensor([range(0,2000)])[0].to(device)\n",
    "y_2 = torch.tensor([range(0,2000)])[0].to(device)\n",
    "train_y = torch.stack([y_1, y_2], dim=0).to(device)\n",
    "\n",
    "hm = torch_geometric.data.Data(\n",
    "    x=sizmek_data.x, edge_index=sizmek_data.edge_index, \n",
    "    edge_attr=None, \n",
    "    y=train_y, \n",
    "    pos=None, \n",
    "    normal=None, \n",
    "    face=None\n",
    ")\n",
    "hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195c335-7398-4147-817f-8a2f46f88f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ZetaDataset(torch_geometric.data.InMemoryDataset):\n",
    "    def __init__(self, root: str, column: str, label: str, feature_cols=None,\n",
    "                 parse_url=False, expand_x=None, transform=None, pre_transform=None\n",
    "        ):\n",
    "        self.root = root\n",
    "        self.column = column\n",
    "        self.label = label\n",
    "        self.feature_cols = feature_cols\n",
    "        self.parse_url = parse_url\n",
    "        self.expand_x = expand_x\n",
    "        super(ZetaDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return [\n",
    "            \"sizmek_bidstream_raw_20210625_10k.csv\", \n",
    "            \"zync_session_tracking_orc_20210625_10k.csv\"\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"ZetaDataset.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        sizmek_path = os.path.join(self.root, self.raw_file_names[0])\n",
    "        zync_path = os.path.join(self.root, self.raw_file_names[1])\n",
    "        \n",
    "        print(\"Loading\", sizmek_path)\n",
    "        x1, edge_index1 = self.process_graph(sizmek_path, self.column[0], self.feature_cols[0])\n",
    "        x2, edge_index2 = self.process_graph(zync_path, self.column[1], self.feature_cols[1])\n",
    "\n",
    "        train_y = self.process_y()\n",
    "        test_y = self.process_y()\n",
    "\n",
    "        data = Data(x1=x1, edge_index1=edge_index1, x2=x2,\n",
    "                    edge_index2=edge_index2, train_y=train_y,\n",
    "                    test_y=test_y)\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def process_graph(self, file_path, column, feature_cols):\n",
    "        print(f\"Processing graph for {file_path} on {column}\")\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        df.columns = [i.split(\".\")[1] for i in df.columns]\n",
    "\n",
    "        # parse URLs\n",
    "        if self.parse_url == True and column in [\"url\", \"referrer\"]:\n",
    "            df[column] = df[column].apply(\n",
    "                lambda x:urlparse(x).netloc if pd.notnull(x) else x\n",
    "            )\n",
    "\n",
    "        # Encode features\n",
    "        feature_enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        features = pd.DataFrame(\n",
    "            feature_enc.fit_transform(df[feature_cols]).toarray(), \n",
    "            columns=feature_enc.get_feature_names(feature_cols)\n",
    "        )\n",
    "\n",
    "        if self.expand_x is not None:\n",
    "            new_cols = [f\"fake_{self.expand_x-i}\" for i in range(self.expand_x - features.shape[1])][::-1]\n",
    "            for column in new_cols:\n",
    "                features[column] = 0\n",
    "        x = torch.tensor(features.values, dtype=torch.float)\n",
    "        \n",
    "        edges = funcs.connect_edges(df, column)\n",
    "        edge_index = torch.tensor(\n",
    "            edges[['source','target']].T.values, dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return x, edge_index\n",
    "\n",
    "    def process_y(self) -> Tensor:\n",
    "        y_1 = torch.tensor([range(0,2000)])[0]\n",
    "        y_2 = torch.tensor([range(0,2000)])[0]\n",
    "        train_y = torch.stack([y_1, y_2], dim=0)\n",
    "        return train_y\n",
    "\n",
    "zeta_data = ZetaDataset(\n",
    "    root=\"./data/\",\n",
    "    column=[\"url\", \"referrer\"], \n",
    "    label=[\"zeta_user_id\", \"client_id\"], \n",
    "    feature_cols=[sizmek_cols, zync_cols], \n",
    "    parse_url=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b53ed-53a1-40f7-bc18-fd9a7620947b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(zeta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd87a01-7f91-4b4b-be9a-daa405626414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sizmek_data = funcs.ZetaData(sizmek_path, \"url\", \"zeta_user_id\", sizmek_cols, parse_url=False)\n",
    "sizmek_model = GCN(zeta_data)\n",
    "\n",
    "# Load and Create Zync Data\n",
    "#zync_data = funcs.ZetaData(zync_path, \"referrer\", \"client_id\", zync_cols, parse_url=False, expand_x=596)\n",
    "zync_model = funcs.GCN(zync_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0c59b-8b63-4db1-a89d-19aaa9546c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "(self, root: str, column: str, target: str, feature_cols=None,\n",
    "                 parse_url=True, expand_x=None, transform=None, pre_transform=None\n",
    "        ):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
